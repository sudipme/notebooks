{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "housing = pd.read_csv('housing.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = housing_df.drop([\"column_name\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seperate Numerical and categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_cat = housing[[\"ocean_proximity\"]]\n",
    "housing_target = housing[\"median_house_value\"]\n",
    "housing_num = housing.drop([\"ocean_proximity\",\"median_house_value\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(housing_num.head())\n",
    "print(housing_cat.head())\n",
    "print(housing_target.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually filling missing values in a column with the median value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing[\"total_bedrooms\"].fillna(housing[\"total_bedrooms\"].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SimpleImputer \n",
    "- Scikit-Learn provides a handy class to take care of missing values: SimpleImputer.\n",
    "- Create a SimpleImputer instance, specifying that we want to replace each attribute’s missing values with the median of that attribute.\n",
    "- median can only be computed on numerical attributes, we need to create a copy of the data without the text attribute(categorical data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy=\"median\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now we can fit the imputer instance to the training data using the fit() method\n",
    "- we cannot be sure that there won’t be any missing values in new data after the system goes live, so it is safer to apply the imputer to all the numerical attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer.fit(housing_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The imputer has simply computed the median of each attribute and stored the result in its statistics_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer.statistics_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now we can use this “trained” imputer to transform the training set by replacing missing values by the learned medians."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = imputer.transform(housing_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The result is a plain NumPy array containing the transformed features. To put it back into a Pandas DataFrame use pd.DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_tr = pd.DataFrame(X, columns=housing_num.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imputer is a scikit learn Estimator so it has the fit method. \n",
    "\n",
    "Also it is transform so it has the transform() method.\n",
    "\n",
    "For transformers we can use the fit_transform() method to fit and transform the data simultaneously. \n",
    "**fit_transform()** is the optimized method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = imputer.fit_transform(housing_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling categorical data\n",
    "\n",
    "- ordinal encoding\n",
    "- Onehot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "housing_cat_encoded = ordinal_encoder.fit_transform(housing_cat)\n",
    "housing_cat_encoded[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_encoder.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "cat_encoder = OneHotEncoder()\n",
    "housing_cat_1hot = cat_encoder.fit_transform(housing_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_cat_1hot.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_cat_1hot_df = pd.DataFrame(housing_cat_1hot.toarray(), columns=cat_encoder.get_feature_names_out([\"ocean_proximity\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_cat_1hot_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "series vs dataframe in pandas df[\"column\"] vs df[[\"column\"]]\n",
    "\n",
    "In Pandas, the behavior you've described is intentional and follows the design of the DataFrame structure.\n",
    "\n",
    "When you use single square brackets `df[\"column\"]`, you are indexing a single column, and the result is a Pandas Series. A Series is essentially a one-dimensional labeled array, and it retains the index of the original DataFrame.\n",
    "\n",
    "On the other hand, when you use double square brackets `df[[\"column\"]]`, you are indexing with a list of column names, even if there is only one column in the list. This syntax is designed to return a DataFrame with the specified column(s). The result is a DataFrame with one or more columns, and it retains the DataFrame structure.\n",
    "\n",
    "Here's a simple example to illustrate:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Creating a DataFrame\n",
    "data = {'A': [1, 2, 3], 'B': [4, 5, 6]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Single square brackets return a Series\n",
    "series_result = df['A']\n",
    "print(type(series_result))  # <class 'pandas.core.series.Series'>\n",
    "\n",
    "# Double square brackets return a DataFrame\n",
    "df_result = df[['A']]\n",
    "print(type(df_result))  # <class 'pandas.core.frame.DataFrame'>\n",
    "```\n",
    "\n",
    "In both cases, you can access the data within the Series or DataFrame using standard Pandas operations. However, the choice between a Series and a DataFrame depends on your specific use case and the structure of the data you are working with."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
