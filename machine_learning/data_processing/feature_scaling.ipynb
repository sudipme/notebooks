{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling\n",
    "\n",
    "Machine Learning algorithms donâ€™t perform well when the input numerical attributes have very different scales. \n",
    "Feature scaling is one of the most important transformations needed to apply to the data.\n",
    "- min-max scaling\n",
    "- standardization\n",
    "  \n",
    "## min-max scaling (normalization)\n",
    "- values are shifted and rescaled so that they end up ranging from 0 to 1.\n",
    "- subtract the min value and divide by the max minus the min.\n",
    "$$(xi-min)/(max-min)$$\n",
    "\n",
    "## Standardization\n",
    "- first subtract the mean value (so standardized values always have a zero mean)\n",
    "- then divide by the standard deviation (so that the resulting distribution has unit variance).\n",
    "- Unlike min-max scaling, standardization does not bound values to a specific range.\n",
    "- standardization is much less affected by outliers\n",
    "$$(xi-mean)/standard deviation$$\n",
    "- scikit learn provide a transformer for that: **StandardScaler**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
