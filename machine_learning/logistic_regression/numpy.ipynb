{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ddb61f43-e822-46d7-9503-16bf96bb6c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "daaed3e8-97e1-4ab5-b321-9eb6c96dd29c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'categories', 'feature_names', 'target_names', 'DESCR', 'details', 'url'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784', version=1, as_frame=False, parser='auto') # as_frame=True will return pandas dataframe\n",
    "mnist.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7868bc1-8a68-48b7-9c03-1babe2ce1ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784) (70000,)\n"
     ]
    }
   ],
   "source": [
    "X,y = mnist[\"data\"], mnist[\"target\"]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "382ca15f-4290-43ac-8fdf-0931e00ee6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc71e5c6-3d24-4cbf-92b7-c0b623ee06c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = X[:10000], X[10000:], y[:10000], y[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6181546b-fa0b-4ca1-a9f1-a8b90787888a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "some_digit = X[0]\n",
    "some_digit_image = some_digit.reshape(28,28)\n",
    "\n",
    "plt.imshow(some_digit_image, cmap = mpl.cm.binary, interpolation=\"nearest\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3679a6-fc77-4b3d-b713-085f1413ed90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def compute_loss(y, y_hat):\n",
    "    m = len(y)\n",
    "    return -1/m * np.sum(y * np.log(y_hat) + (1 - y) * np.log(1 - y_hat))\n",
    "\n",
    "def learning_schedule(t):\n",
    "    t0, t1 = 5, 50\n",
    "    return t0/(t + t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "05bc1b6b-63aa-4668-ae2a-f168e63ce94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X_train, y_train, n_epochs):\n",
    "    m, n = X_train.shape\n",
    "    X_b = np.c_[np.ones((m,1)), X_train]\n",
    "    weights = np.random.randn(n+1,1)\n",
    "    for epoch in range(n_epochs):\n",
    "        for i in range(m):\n",
    "            random_index = np.random.randint(m)\n",
    "            xi = X_b[random_index:random_index + 1]\n",
    "            yi = y_train[random_index:random_index + 1]\n",
    "            z = xi.dot(weights)\n",
    "            y_hat = sigmoid(z)\n",
    "            gradient = xi.T.dot(y_hat - yi)\n",
    "            learning_rate = learning_schedule(epoch*m + i)\n",
    "            weights -= learning_rate * gradient\n",
    "        if epoch % 10 == 0:\n",
    "            loss = -np.mean(yi * np.log(y_hat) + (1 - yi) * np.log(1 - y_hat))\n",
    "\n",
    "            print(f\"Epoch {epoch}: Loss = {loss}\")\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7d043d16-9bc4-48f2-9277-94a68f129f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def learning_schedule(t):\n",
    "    return 5 / (t + 50)\n",
    "\n",
    "def gradient_descent(X_train, y_train, n_epochs):\n",
    "    m, n = X_train.shape\n",
    "    X_b = np.c_[np.ones((m,1)), X_train]\n",
    "    weights = np.random.randn(n+1,1)\n",
    "    for epoch in range(n_epochs):\n",
    "        for i in range(m):\n",
    "            random_index = np.random.randint(m)\n",
    "            xi = X_b[random_index:random_index + 1]\n",
    "            yi = y_train[random_index:random_index + 1]\n",
    "            z = xi.dot(weights)\n",
    "            y_hat = sigmoid(z)\n",
    "\n",
    "            # Clip y_hat to avoid log(0)\n",
    "            y_hat = np.clip(y_hat, 1e-10, 1 - 1e-10)\n",
    "\n",
    "            gradient = xi.T.dot(y_hat - yi)\n",
    "            learning_rate = learning_schedule(epoch*m + i)\n",
    "            weights -= learning_rate * gradient\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            # Calculate the loss for the entire dataset\n",
    "            z_all = X_b.dot(weights)\n",
    "            y_hat_all = sigmoid(z_all)\n",
    "\n",
    "            # Clip y_hat_all to avoid log(0)\n",
    "            y_hat_all = np.clip(y_hat_all, 1e-10, 1 - 1e-10)\n",
    "\n",
    "            loss = -np.mean(y_train * np.log(y_hat_all) + (1 - y_train) * np.log(1 - y_hat_all))\n",
    "            print(f\"Epoch {epoch}: Loss = {loss}\")\n",
    "    \n",
    "    return weights, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ea248be7-5736-4537-be43-285b2e2e8999",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sv/68jyypn920gdpbxqdzpw47200000gn/T/ipykernel_34260/1783546223.py:4: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-z))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss = 3.6616192591171894\n",
      "Epoch 10: Loss = 3.621341895524834\n",
      "Epoch 20: Loss = 3.557158128750358\n",
      "Epoch 30: Loss = 3.5795226122545714\n",
      "Epoch 40: Loss = 3.6030501732685436\n",
      "Epoch 50: Loss = 3.59717107797596\n",
      "Epoch 60: Loss = 3.6236882388052414\n",
      "Epoch 70: Loss = 3.621463331748335\n",
      "Epoch 80: Loss = 3.605049648851341\n",
      "Epoch 90: Loss = 3.5511034289414956\n"
     ]
    }
   ],
   "source": [
    "y_train_5 = (y_train == 5)\n",
    "weights = gradient_descent(X_train, y_train_5, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5d3a95b9-fe8a-4888-8bc6-4294126142e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, weights, threshold=0.05):\n",
    "    X_b = np.insert(X, 0, 1)\n",
    "    z = X_b.dot(weights)\n",
    "    probability = sigmoid(z)\n",
    "    return (probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2401140a-184b-4f81-9fe0-e59c4186d587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sv/68jyypn920gdpbxqdzpw47200000gn/T/ipykernel_34260/1783546223.py:4: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-z))\n"
     ]
    }
   ],
   "source": [
    "r = predict(X[2], weights)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b896b1b-99d8-45d7-a8cc-815a2c29887d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (global)",
   "language": "python",
   "name": "global_python_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
